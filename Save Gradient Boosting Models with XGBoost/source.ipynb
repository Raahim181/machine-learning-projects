{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Gradient Boosting Models with XGBoost\n",
    "\n",
    "XGBoost can be used to create some of the most performant models for tabular data using the gradient boosting algorithm.\n",
    "\n",
    "Once trained, it is often a good practice to save your model to file for later use in making predictions new test and validation datasets and entirely new data.\n",
    "\n",
    "In this post you will discover how to save your XGBoost models to file using the standard Python pickle API.\n",
    "\n",
    "## Serialize Your XGBoost Model with Pickle\n",
    "\n",
    "Pickle is the standard way of serializing objects in Python.\n",
    "\n",
    "You can use the Python [pickle](https://docs.python.org/2/library/pickle.html) API to serialize your machine learning algorithms and save the serialized format to a file, for example:\n",
    "\n",
    "<pre>\n",
    "# save model to file\n",
    "pickle.dump(model, open(\"pima.pickle.dat\", \"wb\"))\n",
    "</pre>\n",
    "\n",
    "Later you can load this file to deserialize your model and use it to make new predictions, for example:\n",
    "\n",
    "<pre>\n",
    "# load model from file\n",
    "loaded_model = pickle.load(open(\"pima.pickle.dat\", \"rb\"))\n",
    "</pre>\n",
    "\n",
    "The example below demonstrates how you can train a XGBoost model on the Pima Indians onset of diabetes [dataset](https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes), save the model to file and later load it to make predictions.\n",
    "\n",
    "The full code listing is provided below for completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.95%\n"
     ]
    }
   ],
   "source": [
    "# Train XGBoost model, save to file using pickle, load and make predictions\n",
    "from numpy import loadtxt\n",
    "import xgboost\n",
    "import pickle\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# load data\n",
    "dataset = loadtxt('pima-indians-diabetes.csv', delimiter=\",\")\n",
    "\n",
    "# split data into X and y\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "# split data into train and test sets\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "# fit model no training data\n",
    "model = xgboost.XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# save model to file\n",
    "pickle.dump(model, open(\"pima.pickle.dat\", \"wb\"))\n",
    "\n",
    "# some time later...\n",
    "\n",
    "# load model from file\n",
    "loaded_model = pickle.load(open(\"pima.pickle.dat\", \"rb\"))\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this example saves your trained XGBoost model to the **pima.pickle.dat** pickle file in the current working directory.\n",
    "\n",
    "After loading the model and making predictions on the training dataset, the accuracy of the model is printed."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
